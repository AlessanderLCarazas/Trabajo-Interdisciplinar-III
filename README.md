# ğŸ“š PROYECTO MEMSUM - ResÃºmenes Extractivos con RL

ImplementaciÃ³n de **MemSum** (Memory-based Summarization) usando **Reinforcement Learning** para generar resÃºmenes extractivos de documentos largos.

---

## ğŸ¯ Â¿QUÃ‰ HACE ESTE PROYECTO?

Genera **resÃºmenes automÃ¡ticos** de textos largos (libros, PDFs, artÃ­culos) seleccionando las oraciones mÃ¡s importantes usando:
- ğŸ§  **Deep Learning** (PyTorch)
- ğŸ® **Reinforcement Learning** (REINFORCE algorithm)
- ğŸ“Š **EvaluaciÃ³n con mÃ©tricas** (ROUGE, BERTScore, Coverage)

---

## ğŸ“ ESTRUCTURA DEL PROYECTO

```
jalar/
â”‚
â”œâ”€â”€ ğŸ“ ARCHIVOS PRINCIPALES
â”‚   â”œâ”€â”€ train.py              â† Entrenar el modelo desde cero
â”‚   â”œâ”€â”€ evaluate.py           â† Evaluar modelo con mÃ©tricas
â”‚   â”œâ”€â”€ app.py                â† Interfaz web bÃ¡sica (solo PDFs)
â”‚   â”œâ”€â”€ app_advanced.py       â† Interfaz web completa (PDF + BookSum)
â”‚   â””â”€â”€ requirements.txt      â† Dependencias a instalar
â”‚
â”œâ”€â”€ ğŸ§  CÃ“DIGO FUENTE (src/)
â”‚   â”œâ”€â”€ model.py              â† Arquitectura MemSum (4 capas)
â”‚   â”œâ”€â”€ trainer.py            â† LÃ³gica de entrenamiento con RL
â”‚   â”œâ”€â”€ data_loader.py        â† Carga dataset BookSum de HuggingFace
â”‚   â”œâ”€â”€ config.py             â† GestiÃ³n de configuraciÃ³n
â”‚   â”œâ”€â”€ fusion.py             â† Capas de fusiÃ³n multimodal
â”‚   â””â”€â”€ __init__.py           â† Inicializador del paquete
â”‚
â”œâ”€â”€ âš™ï¸ CONFIGURACIÃ“N (configs/)
â”‚   â”œâ”€â”€ booksum_config.yaml   â† Config para pruebas rÃ¡pidas (5 epochs)
â”‚   â””â”€â”€ booksum_full_config.yaml â† Config para entrenamiento completo
â”‚
â”œâ”€â”€ ğŸ¤– MODELO ENTRENADO (checkpoints/)
â”‚   â””â”€â”€ best_model.pt         â† Modelo ya entrenado (14 MB) âœ…
â”‚
â”œâ”€â”€ ğŸ“Š DATOS (data/)
â”‚   â””â”€â”€ vocab.pkl             â† Vocabulario procesado
â”‚
â”œâ”€â”€ ğŸ› ï¸ SCRIPTS AUXILIARES (scripts/)
â”‚   â”œâ”€â”€ summarize_pdf.py      â† Resumir archivos PDF
â”‚   â””â”€â”€ summarize_epub.py     â† Resumir libros EPUB
â”‚
â””â”€â”€ ğŸ“– DOCUMENTACIÃ“N
    â”œâ”€â”€ SETUP.md              â† GuÃ­a de instalaciÃ³n paso a paso
    â”œâ”€â”€ CONTENIDO.txt         â† Checklist de archivos incluidos
    â”œâ”€â”€ COMANDOS.txt          â† Lista de comandos importantes â­
    â””â”€â”€ verificar_setup.py    â† Script para verificar instalaciÃ³n
```

---

## ğŸ” Â¿QUÃ‰ HACE CADA ARCHIVO?

### ğŸ“ Scripts Principales

#### `train.py`
**Para quÃ© sirve**: Entrenar el modelo desde cero con el dataset BookSum.
- Usa Reinforcement Learning para aprender a seleccionar oraciones
- Guarda checkpoints cada epoch
- Funciona en CPU y GPU automÃ¡ticamente

#### `evaluate.py`
**Para quÃ© sirve**: Evaluar la calidad del modelo entrenado.
- Calcula mÃ©tricas: ROUGE-1/2/L, BERTScore, Content Coverage
- Compara resÃºmenes generados vs resÃºmenes humanos
- Genera reporte de resultados

#### `app.py`
**Para quÃ© sirve**: Interfaz web bÃ¡sica para resumir PDFs.
- Solo modo PDF (sin mÃ©tricas completas)
- RÃ¡pido y sencillo
- Puerto 8000

#### `app_advanced.py`
**Para quÃ© sirve**: Interfaz web completa con 2 modos.
- **Modo PDF**: Sube PDFs y genera resÃºmenes
- **Modo BookSum**: Selecciona libros y ve todas las mÃ©tricas
- VisualizaciÃ³n de ROUGE, BERTScore y Coverage
- Puerto 8000

---

### ğŸ§  CÃ³digo Fuente (src/)

#### `model.py`
**Para quÃ© sirve**: Define la arquitectura del modelo MemSum.
- **4 capas principales**:
  1. Sentence Encoder (LSTM bidireccional)
  2. Document Encoder (LSTM bidireccional con atenciÃ³n)
  3. Memory (almacena contexto de oraciones seleccionadas)
  4. Decoder (decide quÃ© oraciÃ³n seleccionar)
- Usa embeddings GloVe o Word2Vec

#### `trainer.py`
**Para quÃ© sirve**: LÃ³gica de entrenamiento con Reinforcement Learning.
- Algoritmo REINFORCE para optimizar la selecciÃ³n
- Calcula rewards basados en ROUGE
- Maneja checkpoints y early stopping
- Muestra progreso y pÃ©rdida

#### `data_loader.py`
**Para quÃ© sirve**: Carga y preprocesa el dataset BookSum.
- Descarga automÃ¡ticamente desde HuggingFace
- Tokeniza textos y resÃºmenes
- Crea batches para entrenamiento
- Filtra documentos muy largos

#### `config.py`
**Para quÃ© sirve**: Gestiona la configuraciÃ³n del proyecto.
- Lee archivos YAML
- Define hiperparÃ¡metros por defecto
- Valida configuraciÃ³n

#### `fusion.py`
**Para quÃ© sirve**: Capas de fusiÃ³n para combinar informaciÃ³n.
- Fusiona representaciones de diferentes niveles
- Usado en el document encoder

---

### âš™ï¸ ConfiguraciÃ³n (configs/)

#### `booksum_config.yaml`
**Para quÃ© sirve**: ConfiguraciÃ³n para entrenamiento rÃ¡pido.
- 5 epochs (para pruebas)
- Batch size 2
- Para verificar que todo funciona

#### `booksum_full_config.yaml`
**Para quÃ© sirve**: ConfiguraciÃ³n para entrenamiento completo.
- 40 epochs (entrenamiento serio)
- Mejores resultados
- MÃ¡s tiempo de entrenamiento

**ParÃ¡metros que puedes ajustar**:
- `epochs`: NÃºmero de vueltas al dataset
- `batch_size`: Documentos por batch (1-8)
- `learning_rate`: Velocidad de aprendizaje
- `hidden_dim`: TamaÃ±o de capas ocultas
- `num_layers`: Capas en LSTM

---

### ğŸ¤– Modelo Entrenado (checkpoints/)

#### `best_model.pt`
**Para quÃ© sirve**: Modelo ya entrenado listo para usar.
- 14 MB de tamaÃ±o
- Entrenado con BookSum dataset
- Funciona en CPU y GPU
- **Â¡No necesitas entrenar desde cero!**

---

### ğŸ› ï¸ Scripts Auxiliares (scripts/)

#### `summarize_pdf.py`
**Para quÃ© sirve**: Resume un PDF desde terminal.
- Extrae texto del PDF
- Genera resumen con el modelo
- Guarda resultado en archivo TXT

#### `summarize_epub.py`
**Para quÃ© sirve**: Resume un libro EPUB desde terminal.
- Extrae texto del EPUB
- Genera resumen con el modelo
- Guarda resultado en archivo TXT

---

## ğŸš€ INICIO RÃPIDO

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Verificar instalaciÃ³n
python verificar_setup.py

# 3. Levantar interfaz web
python app_advanced.py

# Listo! Ve a: http://localhost:8000
```

---

## ğŸ“Š MÃ‰TRICAS DE EVALUACIÃ“N

El proyecto evalÃºa resÃºmenes con:

| MÃ©trica | Para quÃ© sirve | Paper |
|---------|----------------|-------|
| **ROUGE-1** | Coincidencia de palabras individuales | MemSum + BookSum |
| **ROUGE-2** | Coincidencia de pares de palabras (fluidez) | MemSum + BookSum |
| **ROUGE-L** | Secuencia mÃ¡s larga comÃºn (estructura) | MemSum + BookSum |
| **BERTScore** | Similitud semÃ¡ntica (significado) | BookSum |
| **Content Coverage** | Cobertura de conceptos clave | BookSum |

---

## ğŸ’» REQUISITOS

- **Python**: 3.8 o superior
- **PyTorch**: 2.0+
- **CUDA** (opcional): Para usar GPU
- **RAM**: 8 GB mÃ­nimo (16 GB recomendado)
- **Espacio**: 500 MB (solo proyecto) + dataset (se descarga automÃ¡tico)

---

## ğŸ“ SOBRE EL PROYECTO

- **Algoritmo**: MemSum (Memory-based Extractive Summarization)
- **TÃ©cnica**: Reinforcement Learning (REINFORCE)
- **Dataset**: BookSum (resÃºmenes de libros completos)
- **Papers**: 
  - BookSum: "BookSum: A Collection of Thousands of Book Summaries"
  - MemSum: "Neural Extractive Summarization with Side Information"

---

## ğŸ“ COMANDOS IMPORTANTES

Ver archivo `COMANDOS.txt` para lista completa de comandos Ãºtiles.

---

## ğŸ› SOLUCIÃ“N DE PROBLEMAS

**Error de CUDA/GPU**: El cÃ³digo funciona automÃ¡ticamente en CPU.

**Error de memoria**: Reduce `batch_size` en el comando de entrenamiento.

**Error de dependencias**: `pip install --upgrade -r requirements.txt`

**Error de NLTK**: `python -c "import nltk; nltk.download('punkt')"`

---

## âœ… VERIFICACIÃ“N

Ejecuta para verificar que todo funciona:
```bash
python verificar_setup.py
```

---

## ğŸ“§ NOTAS

- El modelo ya estÃ¡ entrenado en `checkpoints/best_model.pt`
- El dataset BookSum se descarga automÃ¡ticamente
- Funciona en CPU y GPU (detecta automÃ¡ticamente)
- Compatible con Linux, macOS, Windows

---

Â¡Listo para generar resÃºmenes! ğŸ‰
