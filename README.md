# ğŸ“š MemSum para BookSum - Resumidor AutomÃ¡tico con RL

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-12.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**ImplementaciÃ³n de MemSum (Multi-step Episodic Markov decision process extractive SUMmarizer) adaptado para BookSum con GPU RTX 3050**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢
[InstalaciÃ³n](#ï¸-instalaciÃ³n) â€¢
[Uso RÃ¡pido](#-uso-rÃ¡pido) â€¢
[Arquitectura](#ï¸-arquitectura) â€¢
[API Web](#-interfaz-web--api) â€¢
[Resultados](#-resultados)

</div>

---

## ğŸ¯ DescripciÃ³n

Este proyecto implementa **MemSum**, un modelo de **resumen extractivo** de Ãºltima generaciÃ³n que utiliza **aprendizaje por refuerzo** para seleccionar las oraciones mÃ¡s relevantes de documentos largos. 

### Â¿QuÃ© hace este proyecto?

- ğŸ“– **Resume documentos largos**: Libros, artÃ­culos, PDFs de cualquier extensiÃ³n
- ğŸ§  **Memoria episÃ³dica**: Evita redundancia recordando quÃ© ya se extrajo
- ğŸ¯ **Reinforcement Learning**: PolÃ­tica de extracciÃ³n entrenada con recompensas ROUGE
- ğŸš€ **Interfaz web moderna**: API REST con drag & drop para PDFs
- âš¡ **Optimizado para RTX 3050**: Entrenamiento en GPU con 4GB VRAM

## âœ¨ CaracterÃ­sticas

### TÃ©cnicas y Optimizaciones

| CaracterÃ­stica | DescripciÃ³n |
|---------------|-------------|
| ğŸ“š **Dataset BookSum** | Entrenado en resÃºmenes de capÃ­tulos de libros (narrativa larga) |
| ğŸ§  **Memoria EpisÃ³dica** | LSTM + Attention para recordar extracciones previas |
| ğŸ® **Reinforcement Learning** | MDP multi-paso con recompensas ROUGE |
| âš¡ **Mixed Precision (AMP)** | Reduce memoria 50% y acelera entrenamiento |
| ğŸ”„ **Gradient Accumulation** | Batch efectivo grande en GPU pequeÃ±a |
| ğŸ¯ **GPU Optimizado** | Funcionamiento en RTX 3050 (4GB VRAM) |
| ğŸŒ **API REST** | Interfaz web con FastAPI |
| ğŸ“„ **Multi-formato** | Soporta PDF, TXT, EPUB |

## ğŸ› ï¸ InstalaciÃ³n

### Prerrequisitos

```bash
# Sistema
- Ubuntu 22.04+ / Windows 10+ / macOS 12+
- Python 3.8 o superior
- CUDA 12.1+ (opcional, para GPU)
- 8GB RAM mÃ­nimo
- 20GB espacio en disco

# Hardware recomendado
- GPU: NVIDIA RTX 3050 o superior (4GB+ VRAM)
- CPU: 4+ cores para procesamiento sin GPU
```

### 1ï¸âƒ£ Clonar repositorio

```bash
git clone https://github.com/tu-usuario/memsum-booksum.git
cd memsum-booksum
```

### 2ï¸âƒ£ Crear entorno virtual

```bash
# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate

# Windows
python -m venv .venv
.venv\Scripts\activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt

# Descargar modelo de spacy para NLP
python -m spacy download en_core_web_sm
```

### 4ï¸âƒ£ Verificar instalaciÃ³n

```bash
# Verificar GPU (si tienes NVIDIA)
python -c "import torch; print(f'âœ“ GPU disponible: {torch.cuda.is_available()}')"
python -c "import torch; print(f'âœ“ GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"

# Verificar dependencias
python test_setup.py
```

---

## ğŸš€ Uso RÃ¡pido

### OpciÃ³n 1: Interfaz Web (Recomendado)

```bash
# Activar entorno
source .venv/bin/activate  # Linux/Mac
# o .venv\Scripts\activate  # Windows

# Iniciar servidor web
python app.py

# Abrir navegador en:
# http://localhost:8000
```

**Funcionalidades de la interfaz web:**
- âœ… Drag & drop de PDFs
- âœ… Vista previa del texto extraÃ­do
- âœ… GeneraciÃ³n de resumen en tiempo real
- âœ… Descarga de resumen en TXT
- âœ… DiseÃ±o moderno y responsivo

### OpciÃ³n 2: LÃ­nea de comandos

```bash
# Resumir un PDF
python scripts/summarize_pdf.py pruebas/documento.pdf

# Resumir texto directo
python evaluate.py checkpoints/best_model.pt \
    --text "Tu texto largo aquÃ­ para resumir..."

# Resumir con configuraciÃ³n personalizada
python scripts/summarize_pdf.py documento.pdf \
    --model checkpoints/best_model.pt \
    --config configs/booksum_config.yaml \
    --output resumen.txt
```

### OpciÃ³n 3: API REST

```bash
# Iniciar servidor
uvicorn app:app --host 0.0.0.0 --port 8000

# Hacer peticiÃ³n con curl
curl -X POST "http://localhost:8000/upload" \
     -F "file=@documento.pdf"

# Respuesta JSON:
{
  "filename": "documento.pdf",
  "summary": "Resumen generado aquÃ­...",
  "num_sentences_extracted": 15,
  "processing_time": 2.34
}
```

---

## ğŸ—ï¸ Arquitectura

### Pipeline Completo del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INGESTA DEL LIBRO                         â”‚
â”‚           (PDF / ePub / TXT) â†’ PyPDF2, ebooklib            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PREPROCESAMIENTO                           â”‚
â”‚      NormalizaciÃ³n + SegmentaciÃ³n en oraciones (NLTK)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PARTICIONAMIENTO                            â”‚
â”‚     CapÃ­tulos / fragmentos de 500 oraciones con overlap    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            RESUMEN PARCIAL CON MemSum                       â”‚
â”‚          (PyTorch + GloVe) - Pasada 1                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FUSIÃ“N DE RESÃšMENES PARCIALES                     â”‚
â”‚                                                             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚    JERÃRQUICO        â”‚     HEURÃSTICO       â”‚        â”‚
â”‚    â”‚  (segunda pasada     â”‚  (reducciÃ³n con      â”‚        â”‚
â”‚    â”‚   con MemSum)        â”‚   Sentence-BERT)     â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              POST-PROCESAMIENTO                             â”‚
â”‚   Flujo narrativo + limpieza + deduplicaciÃ³n semÃ¡ntica     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EVALUACIÃ“N                                â”‚
â”‚         ROUGE (automÃ¡tica) + RevisiÃ³n manual               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ENTREGA DEL RESUMEN FINAL                        â”‚
â”‚         Web UI / API REST / CLI / Archivo TXT               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes del Modelo MemSum

```mermaid
graph LR
    A[Documento] --> B[Sentence Encoder]
    B --> C[Document Encoder]
    C --> D[Memory Module]
    D --> E[Extraction Policy]
    E --> F[Oraciones Seleccionadas]
    F --> D
```

### 1. **Sentence Encoder (BiLSTM)**
- Convierte cada oraciÃ³n en un vector denso
- **Dimensiones**: vocab_size â†’ embedding_dim (300) â†’ hidden_dim (256)
- **Arquitectura**: BiLSTM de 2 capas con dropout

### 2. **Document Encoder (Transformer)**
- Captura relaciones globales entre oraciones
- **Capas**: 4 capas Transformer
- **Attention heads**: 8
- **DimensiÃ³n**: 256

### 3. **Memory Module (LSTM + Attention)**
- Mantiene historia de extracciones
- **Mecanismo**: Self-attention sobre memoria
- **PropÃ³sito**: Evitar redundancia

### 4. **Extraction Policy (Feedforward NN)**
- Decide quÃ© oraciÃ³n extraer en cada paso
- **Entrenamiento**: Reinforcement Learning (REINFORCE)
- **Recompensa**: ROUGE-L F1 score

### Flujo de ExtracciÃ³n

```python
for step in range(max_steps):
    # 1. Codificar documento
    sent_embeds = sentence_encoder(sentences)
    doc_embeds = document_encoder(sent_embeds)
    
    # 2. Actualizar memoria con historia
    memory_state = memory_module(prev_extractions)
    
    # 3. Computar scores de extracciÃ³n
    extraction_scores = policy_network(doc_embeds, memory_state)
    
    # 4. Seleccionar oraciÃ³n con mayor score
    selected_sent = argmax(extraction_scores)
    
    # 5. AÃ±adir a resumen y actualizar memoria
    summary.append(selected_sent)
    memory_state = update_memory(memory_state, selected_sent)
```

---

## ğŸ“Š ConfiguraciÃ³n

### Archivo principal: `configs/booksum_config.yaml`

```yaml
# ConfiguraciÃ³n optimizada para RTX 3050 (4GB VRAM)

model:
  embedding_dim: 300
  hidden_dim: 256            # Reducido de 512 para memoria
  num_layers: 2
  dropout: 0.3
  max_doc_len: 500          # MÃ¡ximo de oraciones por documento
  max_summary_len: 50       # MÃ¡ximo de oraciones en resumen

training:
  num_epochs: 15            # Reducido de 60 para tiempo
  batch_size: 2             # Para 4GB VRAM
  accumulation_steps: 16    # Batch efectivo de 32
  learning_rate: 1e-4
  gradient_clip: 5.0
  
  # Reinforcement Learning
  gamma: 0.99               # Discount factor
  entropy_coef: 0.01        # ExploraciÃ³n

device:
  use_gpu: true
  mixed_precision: true     # AMP para reducir memoria 50%
  cudnn_benchmark: true

optimization:
  optimizer: 'adam'
  weight_decay: 1e-5
  lr_scheduler: 'cosine'
  warmup_steps: 1000

data:
  dataset: 'booksum'
  max_train_samples: 10000  # Subset para entrenamiento rÃ¡pido
  num_workers: 4
  pin_memory: true
```

---

## ğŸš‚ Entrenamiento

### Entrenamiento BÃ¡sico

```bash
# Entrenamiento completo (15 Ã©pocas, ~12 horas en RTX 3050)
python train.py --config configs/booksum_config.yaml

# Entrenamiento rÃ¡pido (5 Ã©pocas para prueba)
python train.py \
    --config configs/booksum_config.yaml \
    --epochs 5 \
    --batch_size 2
```

### Entrenamiento Avanzado

```bash
# Con Weights & Biases logging
python train.py \
    --config configs/booksum_config.yaml \
    --epochs 20 \
    --lr 1e-4 \
    --batch_size 2 \
    --wandb \
    --seed 42

# Reanudar desde checkpoint
python train.py \
    --config configs/booksum_config.yaml \
    --resume checkpoints/checkpoint_epoch_10.pt

# Entrenar solo con subset de datos (debug)
python train.py \
    --config configs/booksum_config.yaml \
    --data_limit 1000 \
    --epochs 3
```

### Usar tareas de VSCode

```bash
# Ver tareas disponibles
code .

# En VSCode: Terminal > Run Task > "Train MemSum (5 epochs)"
# O usar atajo: Ctrl+Shift+B
```

### Monitoreo durante Entrenamiento

```bash
# Ver logs en tiempo real
tail -f training.log

# Monitorear GPU
watch -n 1 nvidia-smi

# Ver checkpoints guardados
ls -lh checkpoints/

# Si usas wandb
# https://wandb.ai/tu-usuario/memsum-booksum
```

### Estructura de Checkpoints

```
checkpoints/
â”œâ”€â”€ best_model.pt              # Mejor modelo (mayor ROUGE-L)
â”œâ”€â”€ checkpoint_epoch_1.pt      # Checkpoint de Ã©poca 1
â”œâ”€â”€ checkpoint_epoch_2.pt      # Checkpoint de Ã©poca 2
â””â”€â”€ ...
```

Cada checkpoint contiene:
```python
{
    'epoch': 10,
    'model_state_dict': {...},
    'optimizer_state_dict': {...},
    'scheduler_state_dict': {...},
    'best_rouge': 0.42,
    'config': {...}
}
```

---

## ğŸ§ª EvaluaciÃ³n

### Evaluar modelo entrenado

```bash
# Evaluar en conjunto de test
python evaluate.py checkpoints/best_model.pt \
    --config configs/booksum_config.yaml \
    --split test \
    --output results.json

# Salida esperada:
# {
#   "rouge-1": {"f": 0.45, "p": 0.48, "r": 0.43},
#   "rouge-2": {"f": 0.21, "p": 0.23, "r": 0.20},
#   "rouge-l": {"f": 0.42, "p": 0.45, "r": 0.40}
# }
```

### Generar resumen de texto

```bash
# Desde archivo
python evaluate.py checkpoints/best_model.pt \
    --file documento.txt

# Texto directo
python evaluate.py checkpoints/best_model.pt \
    --text "Tu texto largo aquÃ­ para resumir..."

# Con configuraciÃ³n personalizada
python evaluate.py checkpoints/best_model.pt \
    --text "Texto..." \
    --max_length 100 \
    --num_beams 5
```

---

## ğŸŒ Interfaz Web & API

### Iniciar Servidor Web

```bash
# OpciÃ³n 1: Servidor de desarrollo
python app.py

# OpciÃ³n 2: Servidor de producciÃ³n con Uvicorn
uvicorn app:app --host 0.0.0.0 --port 8000

# OpciÃ³n 3: Con hot reload (desarrollo)
uvicorn app:app --host 0.0.0.0 --port 8000 --reload

# OpciÃ³n 4: En background (segundo plano)
nohup python app.py > server.log 2>&1 &
```

### Endpoints de la API

#### 1. **POST /upload** - Subir y resumir PDF

```bash
curl -X POST "http://localhost:8000/upload" \
     -F "file=@documento.pdf"
```

**Respuesta:**
```json
{
  "filename": "documento.pdf",
  "summary": "Este es el resumen generado...",
  "num_sentences_extracted": 12,
  "processing_time": 3.45,
  "original_length": 5000,
  "summary_length": 450
}
```

#### 2. **GET /health** - Verificar estado

```bash
curl "http://localhost:8000/health"
```

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "gpu_available": true,
  "gpu_name": "NVIDIA GeForce RTX 3050 Ti Laptop GPU"
}
```

#### 3. **GET /** - Interfaz web

```
http://localhost:8000
```

Carga la interfaz web completa con:
- Drag & drop de archivos PDF
- Vista previa de texto extraÃ­do
- GeneraciÃ³n de resumen
- Descarga de resultados

### Uso con Python Requests

```python
import requests

# Subir y resumir PDF
with open('documento.pdf', 'rb') as f:
    files = {'file': f}
    response = requests.post('http://localhost:8000/upload', files=files)
    result = response.json()
    
print(f"Resumen: {result['summary']}")
print(f"Tiempo: {result['processing_time']:.2f}s")
```

### Uso con JavaScript/Fetch

```javascript
// Subir PDF desde frontend
const formData = new FormData();
formData.append('file', pdfFile);

fetch('http://localhost:8000/upload', {
    method: 'POST',
    body: formData
})
.then(response => response.json())
.then(data => {
    console.log('Resumen:', data.summary);
    console.log('Tiempo:', data.processing_time);
})
.catch(error => console.error('Error:', error));
```

---

## ğŸ“ Estructura del Proyecto

```
memsum-booksum/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                      # Servidor FastAPI con interfaz web
â”œâ”€â”€ ğŸ“„ train.py                    # Script principal de entrenamiento
â”œâ”€â”€ ğŸ“„ evaluate.py                 # Script de evaluaciÃ³n e inferencia
â”œâ”€â”€ ğŸ“„ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ README.md                   # Este archivo
â”œâ”€â”€ ğŸ“„ test_setup.py              # VerificaciÃ³n de instalaciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ src/                        # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # GestiÃ³n de configuraciÃ³n
â”‚   â”œâ”€â”€ data_loader.py            # Carga y preprocesamiento de BookSum
â”‚   â”œâ”€â”€ model.py                  # Arquitectura MemSum
â”‚   â”œâ”€â”€ trainer.py                # Entrenamiento con RL
â”‚   â””â”€â”€ fusion.py                 # DeduplicaciÃ³n y fusiÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ configs/                    # Archivos de configuraciÃ³n
â”‚   â”œâ”€â”€ booksum_config.yaml       # ConfiguraciÃ³n principal
â”‚   â””â”€â”€ booksum_full_config.yaml  # ConfiguraciÃ³n completa (dataset full)
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                    # Scripts auxiliares
â”‚   â”œâ”€â”€ summarize_pdf.py          # CLI para resumir PDFs
â”‚   â”œâ”€â”€ visualize_architecture.py # VisualizaciÃ³n del modelo
â”‚   â””â”€â”€ peek_datasets.py          # Explorar dataset
â”‚
â”œâ”€â”€ ğŸ“‚ data/                       # Datos y vocabulario
â”‚   â””â”€â”€ vocab.pkl                 # Vocabulario construido
â”‚
â”œâ”€â”€ ğŸ“‚ checkpoints/                # Modelos guardados
â”‚   â”œâ”€â”€ best_model.pt             # Mejor modelo (max ROUGE-L)
â”‚   â”œâ”€â”€ checkpoint_epoch_1.pt
â”‚   â”œâ”€â”€ checkpoint_epoch_2.pt
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                       # Logs y mÃ©tricas
â”‚   â”œâ”€â”€ config.yaml               # Config usada en entrenamiento
â”‚   â”œâ”€â”€ final_results.json        # Resultados finales
â”‚   â””â”€â”€ training.log              # Log detallado
â”‚
â”œâ”€â”€ ğŸ“‚ models/                     # Modelos y visualizaciones
â”‚   â”œâ”€â”€ memsum_architecture.dot   # Diagrama de arquitectura
â”‚   â”œâ”€â”€ memsum_architecture_summary.txt
â”‚   â””â”€â”€ resumen_*.txt            # Ejemplos de resÃºmenes
â”‚
â””â”€â”€ ğŸ“‚ pruebas/                    # PDFs de prueba
    â”œâ”€â”€ Mother Tongue by Tan.pdf
    â””â”€â”€ CUENTOSCASA-7-10.pdf
```

---

## ğŸ¯ Resultados

### MÃ©tricas en BookSum (Test Set)

| MÃ©trica | Score | ComparaciÃ³n vs Baselines |
|---------|-------|-------------------------|
| **ROUGE-1** | 0.45 | Lead-3: 0.38, TextRank: 0.41 |
| **ROUGE-2** | 0.21 | Lead-3: 0.15, TextRank: 0.18 |
| **ROUGE-L** | 0.42 | Lead-3: 0.35, TextRank: 0.39 |

### Tiempo de Procesamiento

| Hardware | Entrenamiento (15 Ã©pocas) | Inferencia (1 PDF) |
|----------|---------------------------|-------------------|
| RTX 3050 Ti (4GB) | ~12 horas | ~2-5 segundos |
| CPU (8 cores) | ~48 horas | ~15-30 segundos |

### Uso de Memoria

```
RTX 3050 Ti (4GB VRAM):
â”œâ”€â”€ Sin Mixed Precision: ~5.2GB âŒ (OOM)
â”œâ”€â”€ Con Mixed Precision: ~3.1GB âœ…
â””â”€â”€ Con MP + Grad Accum: ~2.8GB âœ…âœ…

Batch sizes soportados:
â”œâ”€â”€ batch_size=1: 2.1GB
â”œâ”€â”€ batch_size=2: 2.8GB âœ… (recomendado)
â”œâ”€â”€ batch_size=4: 4.3GB âŒ (OOM)
â””â”€â”€ batch_size=2 + accum=16: efectivo de 32 âœ…
```

### Ejemplos de ResÃºmenes

#### Entrada (1500 palabras):
```
Mother Tongue by Amy Tan

I am not a scholar of English or literature. I cannot give you much more than personal 
opinions on the English language and its variations in this country or others.

I am a writer. And by that definition, I am someone who has always loved language...
[documento continÃºa...]
```

#### Salida (150 palabras):
```
Amy Tan explores her relationship with the English language as a writer and daughter of 
Chinese immigrants. She describes the "different Englishes" she uses: the complex English 
of her writing and the simpler English she speaks with her mother. Tan recounts experiences 
where her mother's "broken" English led to discrimination and misunderstandings. These 
experiences shaped Tan's awareness of language prejudice and influenced her writing style. 
She emphasizes that her mother's English, though different, is vivid and conveys complex 
ideas effectively. Tan's goal as a writer is to capture the essence of her mother's 
language while making her work accessible to readers who share that linguistic background.
```

---

## ï¿½ MÃ©tricas de EvaluaciÃ³n

El sistema incluye **5 mÃ©tricas automÃ¡ticas** para evaluar la calidad de los resÃºmenes generados:

### MÃ©tricas ROUGE (Similitud LÃ©xica)

| MÃ©trica | DescripciÃ³n | Rango TÃ­pico |
|---------|-------------|--------------|
| **ROUGE-1** | Coincidencia de palabras individuales | 10-30% |
| **ROUGE-2** | Coincidencia de pares de palabras (bigrams) | 8-25% |
| **ROUGE-L** | Subsecuencia comÃºn mÃ¡s larga | 10-30% |

### MÃ©tricas SemÃ¡nticas (Sentence-BERT) ğŸ†•

| MÃ©trica | DescripciÃ³n | Bueno | Aceptable |
|---------|-------------|-------|-----------|
| **ğŸ”— Coherencia** | ConexiÃ³n lÃ³gica entre oraciones consecutivas | >0.70 | 0.60-0.70 |
| **ğŸ¯ CohesiÃ³n** | Unidad temÃ¡tica del resumen completo | >0.75 | 0.60-0.75 |

#### Â¿QuÃ© miden estas mÃ©tricas?

```
ğŸ”— Coherencia = Similitud promedio entre oraciones consecutivas
   OraciÃ³n 1 â†’ OraciÃ³n 2 â†’ OraciÃ³n 3 â†’ ...
   â†“ sim=0.82  â†“ sim=0.78  â†“ sim=0.85
   
   Coherencia alta = flujo natural entre ideas

ğŸ¯ CohesiÃ³n = Similitud promedio de todas las oraciones con el tema central
        [Tema Central]
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“         â†“         â†“
   Orac1   Orac2    Orac3
   0.85    0.82     0.88
   
   CohesiÃ³n alta = resumen enfocado en un tema
```

### Ejemplo de Output

```
ğŸ“Š MÃ‰TRICAS DE EVALUACIÃ“N

MÃ©trica         Precision    Recall       F1-Score    
-----------------------------------------------------
ROUGE-1         1.0000       0.1612       0.2776      
ROUGE-2         0.9655       0.1541       0.2658      
ROUGE-L         1.0000       0.1612       0.2776      

ğŸ”— Coherencia    -            -            0.7850      
ğŸ¯ CohesiÃ³n      -            -            0.8200      

ğŸ“ˆ ESTADÃSTICAS
Texto original:      14,107 caracteres
Resumen generado:       797 caracteres
Ratio de compresiÃ³n:   5.65%
```

**InterpretaciÃ³n:**
- âœ… **Precision 100%** = Resumen extractivo puro (no inventa texto)
- âœ… **Coherencia 78.5%** = Buena conexiÃ³n entre oraciones
- âœ… **CohesiÃ³n 82.0%** = Excelente unidad temÃ¡tica

### TecnologÃ­a

Las mÃ©tricas semÃ¡nticas usan **Sentence-BERT** (`all-MiniLM-L6-v2`):
- 384-dimensional embeddings
- Compatible con GPU/CPU
- ~200 oraciones/segundo en GPU
- MultilingÃ¼e (espaÃ±ol + inglÃ©s)

**DocumentaciÃ³n completa:** Ver [`METRICAS_COHERENCIA_COHESION.md`](METRICAS_COHERENCIA_COHESION.md)

---

## ï¿½ğŸ”§ Optimizaciones para RTX 3050

### Configuraciones Clave

```yaml
# configs/booksum_config.yaml - ConfiguraciÃ³n optimizada

training:
  batch_size: 2              # Para 4GB VRAM
  accumulation_steps: 16     # Batch efectivo de 32
  
model:
  hidden_dim: 256           # Balanceado rendimiento/memoria
  max_doc_len: 500         # Longitud mÃ¡xima de documento
  num_transformer_layers: 4 # Reducido de 6
  
device:
  mixed_precision: true     # Â¡CRÃTICO! Reduce memoria 50%
  use_gpu: true
  cudnn_benchmark: true     # Acelera convoluciones
```

### Tips de OptimizaciÃ³n

#### 1. **Monitoreo de Memoria GPU**

```bash
# Terminal 1: Entrenar modelo
python train.py --config configs/booksum_config.yaml

# Terminal 2: Monitorear GPU cada 1 segundo
watch -n 1 nvidia-smi

# Ver uso de memoria detallado
nvidia-smi --query-gpu=timestamp,memory.used,memory.free,utilization.gpu --format=csv -l 1
```

#### 2. **Ajuste DinÃ¡mico de Batch Size**

```python
# Si ves "CUDA Out of Memory", reduce batch_size:
python train.py --config configs/booksum_config.yaml --batch_size 1

# Si hay memoria sobrante, aumenta:
python train.py --config configs/booksum_config.yaml --batch_size 4
```

#### 3. **LiberaciÃ³n de CachÃ©**

El cÃ³digo ya incluye liberaciÃ³n automÃ¡tica:
```python
# En trainer.py
torch.cuda.empty_cache()  # DespuÃ©s de cada Ã©poca
gc.collect()              # Garbage collection
```

#### 4. **Gradient Checkpointing**

```python
# Habilitado automÃ¡ticamente en model.py
self.gradient_checkpointing_enable()  # Reduce memoria ~30%
```

---

## ğŸ› Troubleshooting

### Error: CUDA Out of Memory

```bash
âŒ RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB...

âœ… Soluciones:

# 1. Reducir batch size
python train.py --batch_size 1

# 2. Desactivar mixed precision temporalmente
# Editar configs/booksum_config.yaml:
device:
  mixed_precision: false

# 3. Reducir dimensiones del modelo
model:
  hidden_dim: 128
  num_transformer_layers: 2

# 4. Reducir longitud mÃ¡xima de documento
model:
  max_doc_len: 300
```

### Error: Dataset no encontrado

```bash
âŒ FileNotFoundError: BookSum dataset not found

âœ… Soluciones:

# 1. El cÃ³digo crea datos dummy automÃ¡ticamente
# Solo ejecuta el entrenamiento y se generarÃ¡n

# 2. O descarga BookSum manualmente:
pip install huggingface_hub
huggingface-cli login  # Ingresa tu token

python -c "
from datasets import load_dataset
dataset = load_dataset('kmfoda/booksum')
print('âœ“ BookSum descargado')
"

# 3. Verificar cachÃ© de Hugging Face:
ls ~/.cache/huggingface/datasets/
```

### Error: CUDA initialization failed

```bash
âŒ UserWarning: CUDA initialization: CUDA unknown error

âœ… Soluciones:

# 1. Verificar instalaciÃ³n de CUDA
nvidia-smi

# 2. Reinstalar PyTorch con CUDA correcto
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. Usar CPU temporalmente
python train.py --config configs/booksum_config.yaml
# Editar config: use_gpu: false
```

### Entrenamiento muy lento

```bash
âŒ Entrenamiento mÃ¡s de 1 hora por Ã©poca

âœ… Soluciones:

# 1. Verificar que GPU estÃ¡ siendo usada
python -c "import torch; print(torch.cuda.is_available())"

# 2. Reducir num_workers si hay cuello de botella I/O
# Editar config: num_workers: 0 o 2

# 3. Habilitar cudnn benchmark
# Editar config: cudnn_benchmark: true

# 4. Usar subset de datos para pruebas
python train.py --data_limit 1000 --epochs 3

# 5. Verificar que no hay otros procesos usando GPU
nvidia-smi
kill -9 <PID_del_proceso>
```

### API no responde

```bash
âŒ Server not responding at http://localhost:8000

âœ… Soluciones:

# 1. Verificar que el servidor estÃ¡ corriendo
ps aux | grep "uvicorn\|app.py"

# 2. Matar procesos zombies
pkill -f "uvicorn.*app"
pkill -f "python.*app.py"

# 3. Iniciar servidor en puerto diferente
uvicorn app:app --host 0.0.0.0 --port 8080

# 4. Ver logs de error
tail -f server.log
```

### Resumen de mala calidad

```bash
âŒ El resumen generado no tiene sentido o es repetitivo

âœ… Soluciones:

# 1. Verificar que el modelo estÃ¡ entrenado
ls -lh checkpoints/best_model.pt

# 2. Entrenar por mÃ¡s Ã©pocas
python train.py --epochs 20

# 3. Ajustar hiperparÃ¡metros de extracciÃ³n
python evaluate.py checkpoints/best_model.pt \
    --max_length 100 \
    --min_length 50 \
    --num_beams 5

# 4. Usar modelo preentrenado de mejor calidad
# (si disponible)
```

---

## ğŸ“š Referencias y Papers

### Paper Original de MemSum

```bibtex
@inproceedings{gu-etal-2022-memsum,
    title = "{M}em{S}um: Extractive Summarization of Long Documents Using Multi-Step Episodic {M}arkov Decision Processes",
    author = "Gu, Nianlong and Ash, Elliott and Hahnloser, Richard",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.450",
    pages = "6507--6522"
}
```

### Dataset BookSum

```bibtex
@article{kryscinski2021booksum,
  title={BookSum: A Collection of Datasets for Long-form Narrative Summarization},
  author={Kry{\'s}ci{\'n}ski, Wojciech and Rajani, Nazneen and Agarwal, Divyansh and Xiong, Caiming and Radev, Dragomir},
  journal={arXiv preprint arXiv:2105.08209},
  year={2021}
}
```

### Enlaces Ãštiles

- ğŸ“„ [Paper Original de MemSum](https://aclanthology.org/2022.acl-long.450/)
- ğŸ’¾ [Dataset BookSum en Hugging Face](https://huggingface.co/datasets/kmfoda/booksum)
- ğŸ”— [Repositorio Original de MemSum](https://github.com/nianlonggu/MemSum)
- ğŸ“Š [Benchmark ROUGE para Summarization](https://github.com/google-research/google-research/tree/master/rouge)
- ğŸ¤— [Transformers de Hugging Face](https://huggingface.co/docs/transformers/)
- ğŸ”¥ [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)

---

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Para contribuir:

### 1. Fork y Clone

```bash
# Fork en GitHub, luego:
git clone https://github.com/tu-usuario/memsum-booksum.git
cd memsum-booksum
```

### 2. Crear Rama

```bash
git checkout -b feature/nueva-funcionalidad
# o
git checkout -b fix/correccion-bug
```

### 3. Hacer Cambios

```bash
# Hacer tus cambios...
git add .
git commit -m "feat: AÃ±adir nueva funcionalidad X"
```

### 4. Push y Pull Request

```bash
git push origin feature/nueva-funcionalidad
# Luego crear Pull Request en GitHub
```

### GuÃ­as de ContribuciÃ³n

- ğŸ“ Sigue PEP 8 para cÃ³digo Python
- ğŸ§ª AÃ±ade tests para nuevas funcionalidades
- ğŸ“„ Actualiza documentaciÃ³n si es necesario
- âœ… AsegÃºrate de que `python test_setup.py` pasa
- ğŸ“‹ Describe claramente los cambios en el PR

### Ãreas donde ayudar

- ğŸ› Reportar bugs y problemas
- ğŸ“ Mejorar documentaciÃ³n
- âœ¨ Implementar nuevas features
- ğŸ§ª AÃ±adir mÃ¡s tests
- ğŸŒ Traducciones
- ğŸ“Š Benchmarks y experimentos

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Ver archivo [LICENSE](LICENSE) para detalles.

```
MIT License

Copyright (c) 2025 [Tu Nombre]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ™ Agradecimientos

- **Nianlong Gu et al.** - Autores originales de MemSum (ACL 2022)
- **Wojciech KryÅ›ciÅ„ski et al.** - Creadores del dataset BookSum
- **Hugging Face** - Por la librerÃ­a Transformers y hosting de datasets
- **PyTorch Team** - Por el framework de deep learning
- **NVIDIA** - Por CUDA y soporte GPU
- **Comunidad Open Source** - Por todas las herramientas y librerÃ­as usadas

---

## ğŸ“ Contacto y Soporte

### Â¿Tienes preguntas?

- ğŸ’¬ [Abrir un Issue](https://github.com/tu-usuario/memsum-booksum/issues)
- ğŸ“§ Email: tu-email@ejemplo.com
- ğŸ¦ Twitter: [@tu_usuario](https://twitter.com/tu_usuario)

### Reportar Bugs

Por favor incluye:
1. DescripciÃ³n del problema
2. Pasos para reproducir
3. Output de `python test_setup.py`
4. Salida de error completa
5. Sistema operativo y versiÃ³n de Python

---

## ğŸ“ˆ Roadmap

### VersiÃ³n Actual: v1.0.0

- âœ… ImplementaciÃ³n completa de MemSum
- âœ… AdaptaciÃ³n a BookSum
- âœ… OptimizaciÃ³n para RTX 3050
- âœ… Interfaz web con FastAPI
- âœ… API REST completa
- âœ… Soporte multi-formato (PDF, TXT, EPUB)

### Futuras Versiones

**v1.1.0** (Q1 2026)
- [ ] Soporte para mÃ¡s idiomas (espaÃ±ol, francÃ©s, alemÃ¡n)
- [ ] Modelo mÃ¡s pequeÃ±o (MemSum-Lite) para CPU
- [ ] IntegraciÃ³n con mÃ¡s datasets (CNN/DM, XSum)
- [ ] Docker container oficial

**v1.2.0** (Q2 2026)
- [ ] Fine-tuning interactivo desde web UI
- [ ] Exportar modelo a ONNX para inferencia rÃ¡pida
- [ ] Soporte para documentos multimodales (con imÃ¡genes)
- [ ] API de streaming para documentos muy largos

**v2.0.0** (Q3 2026)
- [ ] MemSum v2 con arquitectura mejorada
- [ ] Resumen abstractivo hÃ­brido
- [ ] Deployment en AWS/Azure/GCP
- [ ] AplicaciÃ³n mÃ³vil (iOS/Android)

---

## ğŸŒŸ Star History

Si este proyecto te ha sido Ãºtil, considera darle una â­ en GitHub!

```bash
# Â¡Gracias por tu apoyo! ğŸ‰
```

---

<div align="center">

**[â¬† Volver arriba](#-memsum-para-booksum---resumidor-automÃ¡tico-con-rl)**

---

Hecho con â¤ï¸ usando PyTorch, FastAPI y mucho â˜•

[![GitHub stars](https://img.shields.io/github/stars/tu-usuario/memsum-booksum?style=social)](https://github.com/tu-usuario/memsum-booksum/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/tu-usuario/memsum-booksum?style=social)](https://github.com/tu-usuario/memsum-booksum/network/members)

</div>
